{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug_D creation\n",
    "def augmentedD(D):\n",
    "    n = len(D)\n",
    "    a0 = np.array([np.ones(n)]).T\n",
    "    aug_D = np.hstack((a0,D))\n",
    "    return aug_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Function\n",
    "\n",
    "$$\\theta(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(z):\n",
    "    den = 1 + np.exp(-z)\n",
    "    return (1/den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Stochastic Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logisticsga.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSGA(D, y, eta, eps):\n",
    "    y = y[:, 0]\n",
    "    D_aug = augmentedD(D)\n",
    "    d = len(D_aug[0])\n",
    "    n = len(D_aug)\n",
    "    w_0 = np.array([np.zeros(d)]).T\n",
    "    w_prev = w_0\n",
    "    w_curr = w_0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        w_prev = w_curr\n",
    "        w = w_curr\n",
    "            \n",
    "            \n",
    "        r = list(range(n))\n",
    "        random.shuffle(r)  \n",
    "        for i in r:\n",
    "            x_i = np.array([D_aug[i,:]]).T\n",
    "            grad = ( y[i] - theta( np.matmul(w.T, x_i)[0][0] ) )  * x_i\n",
    "            w = w + eta * grad\n",
    "            \n",
    "        w_curr = w\n",
    "        diff = w_curr - w_prev\n",
    "        diff = diff[:, 0]\n",
    "\n",
    "        if(np.dot(diff, diff)**.5 < eps):\n",
    "            y_hat = np.matmul(D_aug, w_curr)\n",
    "            return w, y_hat\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "$\\hat{y}_i = 1$ , if $\\theta(w^Tz_j) \\geq  .5$\n",
    "\n",
    "$\\hat{y}_i = 0$ , if $\\theta(w^Tz_j) <  .5$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_class(y_hat):\n",
    "    y_hat = y_hat[:,0]\n",
    "    n = len(y_hat)\n",
    "    for i in range(n):\n",
    "        if (theta(y_hat[i]) >= .5):\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "            \n",
    "    return np.array([y_hat]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "$$acc = \\frac{\\text{number of cases where,  } \\hat{y}_i = y_i}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    y = y[:,0]\n",
    "    y_hat = y_hat[:,0]\n",
    "    count = 0\n",
    "    for i in range(len(y)):\n",
    "        if(y[i] == y_hat[i]):\n",
    "            count = count + 1\n",
    "    \n",
    "    return count/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8143203883495146\n"
     ]
    }
   ],
   "source": [
    "train = np.genfromtxt(\"Concrete_Data_RNorm_Class_train.txt\", delimiter=',')\n",
    "\n",
    "\n",
    "d = len(train[0])\n",
    "D_train = train[:,np.arange(d-1)]\n",
    "y_train = np.array([train[:,d-1]]).T\n",
    "\n",
    "w , y_hat = logSGA(D_train, y_train, .013, 0.01)\n",
    "    \n",
    "y_hat = binary_class(y_hat)\n",
    "acc = accuracy(y_train, y_hat)\n",
    "print(\"Training Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8495145631067961\n"
     ]
    }
   ],
   "source": [
    "test = np.genfromtxt(\"Concrete_Data_RNorm_Class_test.txt\", delimiter=',')\n",
    "    \n",
    "d = len(test[0])\n",
    "D_test = test[:,np.arange(d-1)]\n",
    "D_aug_test = augmentedD(D_test)\n",
    "\n",
    "y_test = np.array([test[:,d-1]]).T\n",
    "\n",
    "y_hat_test = np.matmul(D_aug_test, w)\n",
    "y_hat_test = binary_class(y_hat_test)\n",
    "acc = accuracy(y_test, y_hat_test)\n",
    "print(\"Testing Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Testing Accuracy:  0.8543689320388349\n",
      "Eta:  0.005\n",
      "With weights...\n",
      "[[-3.50406166]\n",
      " [ 6.21301368]\n",
      " [ 3.0710845 ]\n",
      " [ 1.68333333]\n",
      " [-4.2105264 ]\n",
      " [ 1.76824888]\n",
      " [ 0.1668656 ]\n",
      " [-0.86346841]\n",
      " [ 8.90162392]]\n"
     ]
    }
   ],
   "source": [
    "eta = .001\n",
    "maximum =0\n",
    "max_eta = 0\n",
    "while (eta < .02):\n",
    "    w , y_hat = logSGA(D_train, y_train, eta, 0.01)\n",
    "    y_hat_test = np.matmul(D_aug_test, w)\n",
    "    y_hat_test = binary_class(y_hat_test)\n",
    "    acc = accuracy(y_test, y_hat_test)\n",
    "    if(acc > maximum):\n",
    "        maximum = acc\n",
    "        max_eta = eta\n",
    "    eta = eta + .001\n",
    "print(\"Best Testing Accuracy: \", maximum)\n",
    "print(\"Eta: \", max_eta)\n",
    "print(\"With weights...\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed value\n",
    "\n",
    "Keeping $\\epsilon$ fixed at .01 to keep each logistic regression run less than a second and testing values of $\\eta$ from .001 to .02 we find that the best $\\eta = 0.005$ with training accuracy of .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
